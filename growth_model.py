import numpy as np
import json
import os
import pandas as pd
from datetime import datetime, timedelta

# 1. í™˜ê²½ ì„¤ì •
BASE_TEMP = 10.0

def safe_val(x):
    """NaN/Infë¥¼ JSON ì•ˆì „í•œ Noneìœ¼ë¡œ ë³€í™˜"""
    try:
        if pd.isna(x) or (isinstance(x, float) and (np.isnan(x) or np.isinf(x))):
            return None
        return float(x)
    except:
        return None

def generate_mock_data(days=10, reason=""):
    """v4.0: ì‹¤íŒ¨ ì‹œì—ë„ ë¬´ì¡°ê±´ ì›…ì¥í•œ 10ì¼ ê·¸ë˜í”„ë¥¼ ë³´ì—¬ì£¼ëŠ” ìµœí›„ì˜ ë³´ë£¨"""
    print(f"ğŸ“¡ [AI Mode] Generating mock data (Reason: {reason})")
    end_date = datetime.now().date()
    dates = [(end_date - timedelta(days=i)).strftime('%Y-%m-%d') for i in range(days-1, -1, -1)]
    return {
        "success": True, 
        "demo": True, 
        "error_context": reason,
        "dates": dates,
        "temp": [round(22 + np.sin(i/2)*3, 2) for i in range(days)],
        "humi": [round(60 + np.cos(i/2)*10, 2) for i in range(days)],
        "light": [round(400 + np.sin(i/3)*200, 2) for i in range(days)],
        "ec": [1.5] * days, "ph": [6.5] * days,
        "measured_growth": {"dates": [dates[0], dates[-1]], "ratios": [5, 95]},
        "cumulative_gdd": [round(12.0 * (i+1), 2) for i in range(days)]
    }

def run_analysis_data():
    # ğŸ” v4.4: í¬íŠ¸(8001/8002) ê¸°ë°˜ ìë™ ë°ì´í„° ê²½ë¡œ ë§¤ì¹­
    PORT = str(os.environ.get('PORT', '8007'))
    DATA_DIR = os.environ.get('DATA_DIR', 'data').strip()
    
    # 8001ì´ë©´ seoul_data, 8002ì´ë©´ busan_data ìš°ì„  íƒìƒ‰
    if DATA_DIR == 'data' or not DATA_DIR:
        if PORT == '8001' and os.path.exists('seoul_data'): DATA_DIR = 'seoul_data'
        elif PORT == '8002' and os.path.exists('busan_data'): DATA_DIR = 'busan_data'

    # ìµœì¢… ë””ë ‰í† ë¦¬ ìœ íš¨ì„± í™•ì¸
    if not os.path.exists(DATA_DIR):
        for alt in ['seoul_data', 'busan_data', 'data']:
            if os.path.exists(alt):
                DATA_DIR = alt
                break

    csv_path = os.path.join(DATA_DIR, 'smartfarm_tsdb.csv')
    log_path = os.path.join(DATA_DIR, 'growth_log.json')
    
    try:
        # ğŸ“… 10ì¼ íƒ€ì„ë¼ì¸ ìƒì„±
        end_date = datetime.now().date()
        date_range = [end_date - timedelta(days=i) for i in range(9, -1, -1)]
        timeline_df = pd.DataFrame({'date': date_range})
        
        if not os.path.exists(csv_path):
             return generate_mock_data(10, f"CSV Not Found at {csv_path}")

        # ğŸ“Š ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
        df = pd.read_csv(csv_path)
        if df.empty: return generate_mock_data(10, "CSV is empty")

        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['date'] = df['timestamp'].dt.date
        
        # ğŸ”„ í”¼ë²— í…Œì´ë¸” (ì¼ë³„ í‰ê· )
        # ì¤‘ìš”: device_name ë³„ë¡œ í‰ê· ì„ ë‚´ì–´ ë‚ ì§œë³„ë¡œ ì •ë ¬
        pivot_df = df.pivot_table(index='date', columns='device_name', values='value', aggfunc='mean').reset_index()
        
        # ğŸ¯ ì„¼ì„œëª… ë§¤ì¹­ í‚¤ì›Œë“œ ìµœì í™” (í•œê¸€/ì˜ë¬¸/ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        def find_best_col(df, kws):
            for col in df.columns:
                c = str(col).lower()
                if any(kw.lower() in c for kw in kws): return col
            return None

        t_col = find_best_col(pivot_df, ['ì˜¨ë„', 'temp'])
        h_col = find_best_col(pivot_df, ['ìŠµë„', 'humi'])
        l_col = find_best_col(pivot_df, ['ì¡°ë„', 'light', 'ppfd', 'ê´‘ëŸ‰'])
        e_col = find_best_col(pivot_df, ['ec'])
        p_col = find_best_col(pivot_df, ['ph'])

        # ğŸ”— íƒ€ì„ë¼ì¸ ê°•ì œ ë³‘í•© (Reindex)
        full_df = pd.merge(timeline_df, pivot_df, on='date', how='left').sort_values('date')
        
        res_dates = [d.strftime('%Y-%m-%d') for d in full_df['date']]
        res_temp = [safe_val(x) for x in (full_df[t_col] if t_col is not None else [None]*10)]
        res_humi = [safe_val(x) for x in (full_df[h_col] if h_col is not None else [None]*10)]
        res_light = [safe_val(x) for x in (full_df[l_col] if l_col is not None else [None]*10)]
        res_ec = [safe_val(x) for x in (full_df[e_col] if e_col is not None else [None]*10)]
        res_ph = [safe_val(x) for x in (full_df[p_col] if p_col is not None else [None]*10)]

        # GDD (ì ì‚°ì˜¨ë„) ê³„ì‚° ë¡œì§ ë³´í˜¸
        gdd_vals = []
        for t in res_temp:
            val = max(t - BASE_TEMP, 0) if t is not None else 0
            gdd_vals.append(val)
        cum_gdd = np.cumsum(gdd_vals).tolist()

        # ìƒìœ¡ ì¸¡ì • ë°ì´í„° ë³‘í•©
        measured = {"dates": [], "ratios": []}
        if os.path.exists(log_path):
            try:
                with open(log_path, 'r', encoding='utf-8') as f:
                    log_data = json.load(f)
                    m_df = pd.DataFrame(log_data)
                    if not m_df.empty:
                        m_df['date'] = pd.to_datetime(m_df['date']).dt.date
                        # 10ì¼ íƒ€ì„ë¼ì¸ ë‚´ì˜ ë°ì´í„°ë§Œ í•©ì¹¨
                        merged_g = pd.merge(m_df, timeline_df, on='date', how='inner')
                        measured = {
                            "dates": [d.strftime('%Y-%m-%d') for d in merged_g['date']],
                            "ratios": merged_g['ratio'].tolist()
                        }
            except Exception as ge:
                print(f"âš ï¸ [AI Log] Growth log error: {ge}")

        # âœ… ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "success": True,
            "dates": res_dates,
            "temp": res_temp,
            "humi": res_humi,
            "light": res_light,
            "ec": res_ec,
            "ph": res_ph,
            "measured_growth": measured,
            "cumulative_gdd": [round(v, 2) for v in cum_gdd]
        }

    except Exception as e:
        import traceback
        err_msg = f"{str(e)}\n{traceback.format_exc()}"
        print(f"âŒ [AI Model Engine] Fatal Error: {err_msg}")
        return generate_mock_data(10, err_msg)
