import asyncio
import json
import csv
import os
import random
import sys
from datetime import datetime
from sf_core import ESP32C3Node, SYSTEM_REGISTRY

# Add current directory to sys.path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print(f"ğŸ”§ [System] Python Executable: {sys.executable}")
print(f"ğŸ”§ [System] CWD: {os.getcwd()}")

# Vision Analysis (Optional)
try:
    import vision_analysis
    print("âœ… [Vision] Vision Module Loaded Successfully.")
except ImportError as e:
    print(f"âš ï¸ [Vision] Vision Module Load Failed: {e}")
    vision_analysis = None

def index_to_alpha(n):
    res = ""
    for _ in range(3):
        res = chr(65 + (n % 26)) + res
        n //= 26
    return res

async def tsdb_logger_task(interval=60):
    """
    ì£¼ê¸°ì ìœ¼ë¡œ ëª¨ë“  ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ CSV íŒŒì¼ì— ì‹œê³„ì—´ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    file_path = "data/smartfarm_tsdb.csv"
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(file_path):
        with open(file_path, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(["timestamp", "node_id", "device_id", "device_name", "value", "pin"])

    print(f"ğŸ“ˆ [TSDB] ì‹œê³„ì—´ ë¡œê¹… íƒœìŠ¤í¬ ê°€ë™ (ì£¼ê¸°: {interval}ì´ˆ)")
    
    # ì‹¤ì‹œê°„ ë°ì´í„° ê³µìœ ë¥¼ ìœ„í•œ íŒŒì¼ ê²½ë¡œ (data í´ë”)
    live_data_path = "data/live_data.json"

    while True:
        try:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            log_entries = []
            live_status = {}

            for node_id, node in SYSTEM_REGISTRY.items():
                node_data = {"sensors": [], "actuators": []}
                for sensor in node.sensors.values():
                    status = sensor.get_status()
                    node_data["sensors"].append(status)
                    # CSVìš© ë¡œê·¸ ë°ì´í„° (1ë¶„ ë§ˆë‹¤)
                    # ì—¬ê¸°ì„œëŠ” 2ì´ˆë§ˆë‹¤ live_dataë¥¼ ë§Œë“¤ê³ , 60ì´ˆë§ˆë‹¤ CSVë¥¼ ê¸°ë¡í•˜ëŠ” ë¡œì§ì„ í†µí•©
                
                for act in node.actuators.values():
                    node_data["actuators"].append({
                        "id": act.device_id,
                        "name": act.name,
                        "state": act.state
                    })
                live_status[node_id] = node_data

            # 1. 2ì´ˆë§ˆë‹¤ ì‹¤ì‹œê°„ JSON ì—…ë°ì´íŠ¸ (ì›ìì  ì €ì¥: ì„ì‹œ íŒŒì¼ ì‚¬ìš© í›„ ì´ë¦„ ë³€ê²½)
            with open(live_data_path + ".tmp", 'w', encoding='utf-8') as f:
                json.dump({"timestamp": timestamp, "nodes": live_status}, f, ensure_ascii=False, indent=2)
            os.replace(live_data_path + ".tmp", live_data_path)

            # 2. 60ì´ˆë§ˆë‹¤ CSV ëˆ„ì  (ê°„ë‹¨í•œ ì¹´ìš´í„° ì‚¬ìš©)
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ë§¤ ë£¨í”„(2ì´ˆ)ë§ˆë‹¤ live_dataë¥¼ ì“°ì§€ë§Œ CSVëŠ” intervalì— ë”°ë¦„
            # ìˆ˜ì •: intervalì„ 2ì´ˆë¡œ ì¡ê³ , CSV ì €ì¥ì€ ë³„ë„ ì¹´ìš´í„°ë¡œ ì²˜ë¦¬
            if not hasattr(tsdb_logger_task, '_csv_counter'):
                tsdb_logger_task._csv_counter = 0
            
            tsdb_logger_task._csv_counter += 2
            if tsdb_logger_task._csv_counter >= interval:
                tsdb_logger_task._csv_counter = 0
                for node_id, node_data in live_status.items():
                    for s in node_data["sensors"]:
                        log_entries.append([timestamp, node_id, s['id'], s['name'], s['val'], s['pin']])
                
                if log_entries:
                    with open(file_path, 'a', newline='', encoding='utf-8-sig') as f:
                        writer = csv.writer(f)
                        writer.writerows(log_entries)
                    print(f"ğŸ“Š [TSDB] {timestamp} ì´ë ¥ ë°ì´í„° ì €ì¥ ì™„ë£Œ.")
            
        except Exception as e:
            print(f"âš ï¸ [TSDB/Live Error] {e}")
        
        await asyncio.sleep(2) # ì‹¤ì‹œê°„ì„±ì„ ìœ„í•´ 2ì´ˆ ì£¼ê¸°ë¡œ ë³€ê²½

async def web_server_task():
    """
    ë¸Œë¼ìš°ì €ì˜ CORS ì •ì±…(file:// ì œí•œ)ì„ í”¼í•˜ê¸° ìœ„í•´
    í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ì›¹ ì„œë²„ë¡œ í˜¸ìŠ¤íŒ…í•©ë‹ˆë‹¤.
    ë˜í•œ /api/history ì—”ë“œí¬ì¸íŠ¸ë¥¼ í†µí•´ CSV ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.
    """
    import http.server
    import socketserver
    import urllib.parse
    
    PORT = 8000

    class SmartFarmHandler(http.server.SimpleHTTPRequestHandler):
        def do_GET(self):
            # ë£¨íŠ¸ ê²½ë¡œ ì ‘ì† ì‹œ ëŒ€ì‹œë³´ë“œë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
            if self.path == '/':
                self.send_response(301)
                self.send_header('Location', '/html/index.html')
                self.end_headers()
                return

            # API ìš”ì²­ ì²˜ë¦¬
            if self.path.startswith('/api/history'):
                self.handle_history_api()
            elif self.path.startswith('/api/journal'):
                self.handle_journal_list()
            elif self.path.startswith('/api/growth'):
                self.handle_growth_list()
            else:
                # ê¸°ë³¸ ì •ì  íŒŒì¼ ì œê³µ
                super().do_GET()

        def do_POST(self):
            # API ìš”ì²­ ì²˜ë¦¬ (POST)
            if self.path.startswith('/api/journal'):
                self.handle_journal_post()
            elif self.path.startswith('/api/analyze_growth'):
                self.handle_growth_analysis()
            else:
                self.send_error(404, "Endpoint not found")

        def handle_growth_analysis(self):
            try:
                # 1. Body ì½ê¸° (Target Image URL)
                content_length = int(self.headers['Content-Length'])
                post_data = self.rfile.read(content_length)
                req_json = json.loads(post_data.decode('utf-8'))
                image_url = req_json.get('url', '')
                
                if not image_url:
                    self.send_error(400, "Image URL is missing")
                    return
                
                # 2. Vision Analysis ì‹¤í–‰
                if vision_analysis:
                    try:
                        result = vision_analysis.analyze_plant_growth(image_url)
                        
                        # [NEW] ë¶„ì„ ê²°ê³¼ íŒŒì¼ ì €ì¥
                        if result.get('success'):
                            log_file = "data/growth_log.json"
                            logs = []
                            if os.path.exists(log_file):
                                try:
                                    with open(log_file, 'r', encoding='utf-8') as f:
                                        logs = json.load(f)
                                except: pass
                            
                            # Add log entry
                            logs.append({
                                "date": result['timestamp'],
                                "ratio": result['ratio'],
                                "pixels": result['green_pixels']
                            })
                            
                            with open(log_file, 'w', encoding='utf-8') as f:
                                json.dump(logs, f, indent=2)

                    except Exception as e:
                        result = {"error": f"Vision Engine Error: {str(e)}"}
                else:
                    result = {"error": "Vision Module Not Loaded. (Check terminal logs for import error)"}
                
                # 3. ê²°ê³¼ ë°˜í™˜
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps(result).encode('utf-8'))
                
            except Exception as e:
                print(f"Analysis API Error: {e}")
                self.send_error(500, str(e))

        def handle_journal_post(self):
            # ... (Existing Code) ...
            try:
                # 1. Body ì½ê¸°
                content_length = int(self.headers['Content-Length'])
                post_data = self.rfile.read(content_length)
                entry = json.loads(post_data.decode('utf-8'))
                
                # 2. íŒŒì¼ì— ì €ì¥ (prepend)
                file_path = "data/journal.json"
                journals = []
                
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        try:
                            journals = json.load(f)
                        except json.JSONDecodeError:
                            journals = []
                
                journals.insert(0, entry) # ìµœì‹ ìˆœ
                
                with open(file_path, 'w', encoding='utf-8') as f:
                    json.dump(journals, f, ensure_ascii=False, indent=2)
                
                self.send_response(200)
                self.end_headers()
                self.wfile.write(b"OK")
                
            except Exception as e:
                print(f"Journal Save Error: {e}")
                self.send_error(500, str(e))


        def handle_history_api(self):
            try:
                # 1. íŒŒë¼ë¯¸í„° íŒŒì‹±
                query = urllib.parse.urlparse(self.path).query
                params = urllib.parse.parse_qs(query)
                target_date = params.get('date', [None])[0] # YYYY-MM-DD
                
                if not target_date:
                    self.send_error(400, "Missing 'date' parameter")
                    return

                # 2. CSV ì½ê¸° ë° í•„í„°ë§
                file_path = "data/smartfarm_tsdb.csv"
                result_data = {"labels": [], "temp": [], "humi": []}
                
                if os.path.exists(file_path):
                    # Try multiple encodings
                    encodings = ['utf-8-sig', 'utf-8', 'cp949', 'euc-kr']
                    lines = []
                    
                    for enc in encodings:
                        try:
                            with open(file_path, 'r', encoding=enc) as f:
                                lines = f.readlines()
                            break # Success
                        except UnicodeDecodeError:
                            continue
                            
                    if lines:
                        reader = csv.DictReader(lines)
                        print(f"ğŸ“– [History API] {target_date} ì¡°íšŒ ìš”ì²­ (Encoding: {enc})")
                        
                        count = 0
                        for row in reader:
                            # timestamp format: YYYY-MM-DD HH:MM:SS
                            ts = row.get('timestamp', '')
                            if ts.startswith(target_date):
                                count += 1
                                # ì‹œê°„ë§Œ ì¶”ì¶œ (HH:MM)
                                time_str = ts.split(' ')[1][:5]
                                
                                # ë°ì´í„° ë¶„ë¥˜
                                dev_name = row.get('device_name', '')
                                val_str = row.get('value', '0')
                                pin = row.get('pin', '')
                                
                                try:
                                    val = float(val_str)
                                except ValueError:
                                    continue
                                
                                # ì°¨íŠ¸ìš© ë°ì´í„° ìˆ˜ì§‘
                                # AAD001(Temp) or Device Name contains 'ì˜¨ë„'
                                if "ì˜¨ë„" in dev_name or "Temp" in dev_name:
                                    result_data["temp"].append({"t": time_str, "y": val})
                                elif "ìŠµë„" in dev_name or "Humi" in dev_name:
                                    result_data["humi"].append({"t": time_str, "y": val})
                        
                        print(f"âœ… [History API] {count}ê±´ì˜ ë°ì´í„° ê²€ìƒ‰ë¨. (Temp: {len(result_data['temp'])}, Humi: {len(result_data['humi'])})")
                    else:
                        print(f"âš ï¸ [History API] CSV ì½ê¸° ì‹¤íŒ¨ (ëª¨ë“  ì¸ì½”ë”© ì‹œë„)")
                else:
                    print(f"âš ï¸ [History API] {file_path} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                
                # 3. ì‹œê°„ìˆœ ì •ë ¬ ë° ë³‘í•© (ê°„ì†Œí™”ëœ ë¡œì§)
                # ì‹¤ì œ ê·¸ë˜í”„ë¥¼ ìœ„í•´ì„œëŠ” ë¼ë²¨(ì‹œê°„)ì„ í†µì¼í•´ì•¼ í•˜ë¯€ë¡œ, ê°„ë‹¨íˆ ìˆ˜ì§‘ëœ ìˆœì„œëŒ€ë¡œ ë°˜í™˜í•˜ê±°ë‚˜
                # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ì›ë³¸ ë°ì´í„°ë¥¼ ì¤Œ. ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë°˜í™˜.
                
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps(result_data).encode('utf-8'))
                
            except Exception as e:
                print(f"API Error: {e}")
                self.send_error(500, str(e))
        
        def handle_journal_list(self):
            try:
                file_path = "data/journal.json"
                journals = []
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        try:
                            journals = json.load(f)
                        except: 
                            pass
                
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps(journals).encode('utf-8'))
            except Exception as e:
                self.send_error(500, str(e))
        
        def handle_growth_list(self):
            try:
                file_path = "data/growth_log.json"
                logs = []
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        try:
                            logs = json.load(f)
                        except: pass
                
                self.send_response(200)
                self.send_header('Content-type', 'application/json')
                self.end_headers()
                self.wfile.write(json.dumps(logs).encode('utf-8'))
            except Exception as e:
                self.send_error(500, str(e))

    # í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ ì„œë¹™í•˜ëŠ” í•¸ë“¤ëŸ¬ ìƒì„±
    handler = list # python 3.7+ workaround not needed for class based
    
    while PORT < 8010:
        try:
            # socketserver.TCPServerëŠ” ë¸”ë¡œí‚¹ì´ë¯€ë¡œ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
            # directory=os.getcwd()ëŠ” SimpleHTTPRequestHandlerì˜ ê¸°ëŠ¥ì´ë¯€ë¡œ ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ì—ì„œëŠ” super().__init__ì—ì„œ ì²˜ë¦¬ë¨
            # í•˜ì§€ë§Œ ë‹¤ì¤‘ ìƒì†ì„ í”¼í•˜ê¸° ìœ„í•´ partial ëŒ€ì‹  ì§ì ‘ í´ë˜ìŠ¤ ì‚¬ìš©
            
            # íŒŒì´ì¬ 3.7+ ThreadingHTTPServer ê¶Œì¥ë˜ì§€ë§Œ í˜¸í™˜ì„± ìœ„í•´ TCPServer ì‚¬ìš©
            with socketserver.TCPServer(("", PORT), SmartFarmHandler) as httpd:
                print(f"ğŸŒ [WEB] ì„œë²„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤: http://localhost:{PORT}/html/index.html")
                print(f"   ã„´ API ì—”ë“œí¬ì¸íŠ¸: http://localhost:{PORT}/api/history")
                await asyncio.to_thread(httpd.serve_forever)
                break
        except OSError:
            PORT += 1

async def dynamic_coordinator_task():
    """
    í•˜ë£¨ 4ë²ˆ(00, 06, 12, 18ì‹œ) ë‚ ì§œë¥¼ ì ê²€í•˜ì—¬ êµ¬ì—­ë³„ ì¬ë°° ë‹¨ê³„ ë° ì„ê³„ê°’ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    ì´ˆê¸° ì‹¤í–‰ ì‹œ 1íšŒ ì¦‰ì‹œ ë™ê¸°í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    CHECK_HOURS = {0, 6, 12, 18}
    print(f"ğŸ“… [Coordinator] ì •ê¸° ì—…ë°ì´íŠ¸ ëª¨ë“œ ê°€ë™ (ì˜ˆì • ì‹œê°„: {sorted(list(CHECK_HOURS))}ì‹œ)")
    
    last_run_hour = -1
    last_processed_stages = {} # {node_id: last_recipe}
    first_run = True

    while True:
        try:
            now = datetime.now()
            # ì •í•´ì§„ ì‹œê°„ì´ê±°ë‚˜ ì´ˆê¸° ì‹¤í–‰ì¸ ê²½ìš°
            if first_run or (now.hour in CHECK_HOURS and now.hour != last_run_hour):
                # 1. ì„¤ì • ë¡œë“œ (data í´ë”)
                with open('data/zone_config.json', 'r', encoding='utf-8') as f:
                    zones = json.load(f)
                
                for zone in zones:
                    zone_id_prefix = zone['id']
                    crop = zone.get('crop', 'none')
                    schedule = zone.get('schedule', {})
                    
                    # 2. í˜„ì¬ ë‚ ì§œì— ë”°ë¥¸ ì¬ë°° ë‹¨ê³„ ê²°ì •
                    current_stage = "sowing"
                    sorted_stages = sorted(
                        [(k, datetime.strptime(v, "%Y-%m-%d")) for k, v in schedule.items()],
                        key=lambda x: x[1], reverse=True
                    )
                    for stage, date in sorted_stages:
                        if now >= date:
                            current_stage = stage
                            break
                    
                    target_recipe = f"{crop}.{current_stage}"
                    
                    # 3. í•´ë‹¹ êµ¬ì—­ì˜ ë…¸ë“œë“¤ì„ ì°¾ì•„ ì„ê³„ê°’ ì—…ë°ì´íŠ¸
                    for node_id, node in SYSTEM_REGISTRY.items():
                        if node_id.startswith(zone_id_prefix):
                            if last_processed_stages.get(node_id) != target_recipe:
                                success = node.update_thresholds(target_recipe)
                                if success:
                                    prefix = "ğŸš€ [Initial]" if first_run else f"â° [{now.hour:02d}:00]"
                                    print(f"{prefix} {node_id} ë‹¨ê³„ í™•ì¸: {target_recipe} ì„ê³„ê°’ ì ìš©")
                                    last_processed_stages[node_id] = target_recipe

                last_run_hour = now.hour
                first_run = False

        except Exception as e:
            print(f"âš ï¸ [Coordinator Error] {e}")
        
        # 1ë¶„ ë‹¨ìœ„ë¡œ ì²´í¬
        await asyncio.sleep(60)

async def main():
    # 1. íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ (data í´ë”)
    try:
        with open('data/config.json', 'r', encoding='utf-8') as f:
            config_data = json.load(f)
    except FileNotFoundError:
        print("data/config.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        return

    all_tasks = []
    print(f"[{len(config_data)}ê°œì˜ ë…¸ë“œ ì„¤ì • ë¡œë“œ ì™„ë£Œ...]")

    for node_cfg in config_data:
        node_id = node_cfg['id']
        node = ESP32C3Node(node_id)
        node.provision(node_cfg)
        
        # í• ë‹¹ëœ í•€ ì •ë³´ ì¶œë ¥
        print(f"   [{node_id}] Pin Map: ", end="")
        pin_info = [f"{dev_id}({info['pin']})" for dev_id, info in node.get_pin_map().items()]
        print(", ".join(pin_info))
        
        # ë¹„ë™ê¸° ì‹¤í–‰ ì¶”ê°€
        interval = random.uniform(4, 6)
        all_tasks.append(node.run_forever(interval=interval))

    # 2. íƒœìŠ¤í¬ ì¶”ê°€
    all_tasks.append(tsdb_logger_task(interval=60))
    all_tasks.append(web_server_task())
    all_tasks.append(dynamic_coordinator_task())

    print(f"\n[ì‹¤í–‰ ì‹œì‘] ëª¨ë“  ë…¸ë“œì™€ í†µí•© ì„œë²„ê°€ ì‘ë™í•©ë‹ˆë‹¤.")
    print("------------------------------------------------------------------")

    try:
        # ëª¨ë“  íƒœìŠ¤í¬ê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ë¬´í•œ ì‹¤í–‰
        await asyncio.gather(*all_tasks)
    except KeyboardInterrupt:
        print("\n[ì •ì§€] ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí–ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n[ì˜¤ë¥˜ ë°œìƒ] {e}")

if __name__ == "__main__":
    asyncio.run(main())
